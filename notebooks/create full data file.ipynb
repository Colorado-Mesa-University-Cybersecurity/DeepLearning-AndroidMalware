{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Full Feature Full Data File\n",
    "The goal of this notebook is to transform the data (AndMal2017 Part One) from the convoluted directory system acquired from the Canadian Institute for Cybersecurity (CIC) at the University of New Brunswick (UNB). The notebook will be a little longer and repetitive than other notebooks since we are repeating the same task multiple times. However, hopefully all will become clear soon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "We are using the `pandas` and `glob` libraries to import and easily manage the data. This simplifies the process considerably. Below, the `path` variable is defined as the relative path the CIC-AndMal2017 Part One dataset. If we look at my file directory...\n",
    "\n",
    "```\n",
    "$ find ../../ -maxdepth 1 -type d\n",
    "\n",
    "../../DeepLearning-AndroidMalware\n",
    "../../malware_dataset\n",
    "```\n",
    "...we can see where my malware_dataset directory is located with respect to the repository. If we look into this directory, we can see our data categories.\n",
    "```\n",
    "$ find ../../malware_dataset/ -maxdepth 1 -type d\n",
    "\n",
    "./malware_dataset/Adware\n",
    "./malware_dataset/Benign\n",
    "./malware_dataset/Ransomware\n",
    "./malware_dataset/SMSmalware\n",
    "./malware_dataset/Scareware\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../malware_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the 'Adware' files below. This creates a list of all of the `csv` files at a depth of two below the 'Adware' directory. Additionally, we initialize an empty data frame for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "allFiles = glob.glob(path + '/Adware/*/*.csv')\n",
    "frame = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the 'Adware' files available, all we have to do is read in each file and add it to a running list of dataframes we've acquired. Once we've brought all of them in, we `concat` them to the empty dataframe we have from before. We can see the first five instances below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.217.1.170-10.42.0.151-443-42321-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>42321</td>\n",
       "      <td>172.217.1.170</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 12:05:44</td>\n",
       "      <td>193014</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_SHUANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.217.2.110-10.42.0.151-443-46111-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>46111</td>\n",
       "      <td>172.217.2.110</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 12:05:45</td>\n",
       "      <td>22499</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_SHUANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.42.0.151-31.13.71.37-43608-443-6</td>\n",
       "      <td>31.13.71.37</td>\n",
       "      <td>443</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>43608</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 12:05:48</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_SHUANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.42.0.151-31.13.71.37-43608-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>43608</td>\n",
       "      <td>31.13.71.37</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 12:05:48</td>\n",
       "      <td>1579</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_SHUANET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.42.0.151-67.222.111.118-60474-443-6</td>\n",
       "      <td>10.42.0.151</td>\n",
       "      <td>60474</td>\n",
       "      <td>67.222.111.118</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 12:05:54</td>\n",
       "      <td>735871</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_SHUANET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Flow ID    Source IP   Source Port  \\\n",
       "0   172.217.1.170-10.42.0.151-443-42321-6  10.42.0.151         42321   \n",
       "1   172.217.2.110-10.42.0.151-443-46111-6  10.42.0.151         46111   \n",
       "2     10.42.0.151-31.13.71.37-43608-443-6  31.13.71.37           443   \n",
       "3     10.42.0.151-31.13.71.37-43608-443-6  10.42.0.151         43608   \n",
       "4  10.42.0.151-67.222.111.118-60474-443-6  10.42.0.151         60474   \n",
       "\n",
       "   Destination IP   Destination Port   Protocol            Timestamp  \\\n",
       "0   172.217.1.170                443          6  14/06/2017 12:05:44   \n",
       "1   172.217.2.110                443          6  14/06/2017 12:05:45   \n",
       "2     10.42.0.151              43608          6  14/06/2017 12:05:48   \n",
       "3     31.13.71.37                443          6  14/06/2017 12:05:48   \n",
       "4  67.222.111.118                443          6  14/06/2017 12:05:54   \n",
       "\n",
       "    Flow Duration   Total Fwd Packets   Total Backward Packets  ...  \\\n",
       "0          193014                   6                        7  ...   \n",
       "1           22499                   1                        2  ...   \n",
       "2              15                   2                        0  ...   \n",
       "3            1579                   3                        0  ...   \n",
       "4          735871                  11                       10  ...   \n",
       "\n",
       "    min_seg_size_forward  Active Mean   Active Std   Active Max   Active Min  \\\n",
       "0                     32          0.0          0.0          0.0          0.0   \n",
       "1                     32          0.0          0.0          0.0          0.0   \n",
       "2                     32          0.0          0.0          0.0          0.0   \n",
       "3                     32          0.0          0.0          0.0          0.0   \n",
       "4                     32          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Idle Mean   Idle Std   Idle Max   Idle Min           Label  \n",
       "0        0.0        0.0        0.0        0.0  ADWARE_SHUANET  \n",
       "1        0.0        0.0        0.0        0.0  ADWARE_SHUANET  \n",
       "2        0.0        0.0        0.0        0.0  ADWARE_SHUANET  \n",
       "3        0.0        0.0        0.0        0.0  ADWARE_SHUANET  \n",
       "4        0.0        0.0        0.0        0.0  ADWARE_SHUANET  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for fille in allFiles:\n",
    "    df = pd.read_csv(fille, index_col=None, header=0)\n",
    "    templist.append(df)\n",
    "frame = pd.concat(templist)\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to rename the dataframe to `df` because that's what I'm used to, but it's kind of a useless step. You may notice that if we output the column names in the next cell, they're all <i>cattywampus</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "Flow ID\n",
      " Source IP\n",
      " Source Port\n",
      " Destination IP\n",
      " Destination Port\n",
      " Protocol\n",
      " Timestamp\n",
      " Flow Duration\n",
      " Total Fwd Packets\n",
      " Total Backward Packets\n",
      "Total Length of Fwd Packets\n",
      " Total Length of Bwd Packets\n",
      " Fwd Packet Length Max\n",
      " Fwd Packet Length Min\n",
      " Fwd Packet Length Mean\n",
      " Fwd Packet Length Std\n",
      "Bwd Packet Length Max\n",
      " Bwd Packet Length Min\n",
      " Bwd Packet Length Mean\n",
      " Bwd Packet Length Std\n",
      "Flow Bytes/s\n",
      " Flow Packets/s\n",
      " Flow IAT Mean\n",
      " Flow IAT Std\n",
      " Flow IAT Max\n",
      " Flow IAT Min\n",
      "Fwd IAT Total\n",
      " Fwd IAT Mean\n",
      " Fwd IAT Std\n",
      " Fwd IAT Max\n",
      " Fwd IAT Min\n",
      "Bwd IAT Total\n",
      " Bwd IAT Mean\n",
      " Bwd IAT Std\n",
      " Bwd IAT Max\n",
      " Bwd IAT Min\n",
      "Fwd PSH Flags\n",
      " Bwd PSH Flags\n",
      " Fwd URG Flags\n",
      " Bwd URG Flags\n",
      " Fwd Header Length\n",
      " Bwd Header Length\n",
      "Fwd Packets/s\n",
      " Bwd Packets/s\n",
      " Min Packet Length\n",
      " Max Packet Length\n",
      " Packet Length Mean\n",
      " Packet Length Std\n",
      " Packet Length Variance\n",
      "FIN Flag Count\n",
      " SYN Flag Count\n",
      " RST Flag Count\n",
      " PSH Flag Count\n",
      " ACK Flag Count\n",
      " URG Flag Count\n",
      " CWE Flag Count\n",
      " ECE Flag Count\n",
      " Down/Up Ratio\n",
      " Average Packet Size\n",
      " Avg Fwd Segment Size\n",
      " Avg Bwd Segment Size\n",
      " Fwd Header Length.1\n",
      "Fwd Avg Bytes/Bulk\n",
      " Fwd Avg Packets/Bulk\n",
      " Fwd Avg Bulk Rate\n",
      " Bwd Avg Bytes/Bulk\n",
      " Bwd Avg Packets/Bulk\n",
      "Bwd Avg Bulk Rate\n",
      "Subflow Fwd Packets\n",
      " Subflow Fwd Bytes\n",
      " Subflow Bwd Packets\n",
      " Subflow Bwd Bytes\n",
      "Init_Win_bytes_forward\n",
      " Init_Win_bytes_backward\n",
      " act_data_pkt_fwd\n",
      " min_seg_size_forward\n",
      "Active Mean\n",
      " Active Std\n",
      " Active Max\n",
      " Active Min\n",
      "Idle Mean\n",
      " Idle Std\n",
      " Idle Max\n",
      " Idle Min\n",
      " Label\n"
     ]
    }
   ],
   "source": [
    "df = frame\n",
    "print('Columns:')\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, right, I hear what you're saying...\n",
    "<pre><i>\"What's with all these random spaces, mate? \n",
    "    How am I supposed to queue anything up like this?\"</i></pre>\n",
    "While I can't explain why this stupid problem exists, I have a stupid solution in the next cell. We'll just remove the first space in a column's name if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming columns with spaces...done\n"
     ]
    }
   ],
   "source": [
    "# Remove the spaces in front of some of the column names\n",
    "#  Without this, it is really annoying to try to pull up a column with random spaces in the front\n",
    "print('Renaming columns with spaces...', end='')\n",
    "cols = {}\n",
    "for name in df.columns:\n",
    "    if name[0] is ' ':\n",
    "        cols[name] = name[1:]\n",
    "df.rename(cols, axis=1, inplace=True, errors='raise')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check out the columns again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "Flow ID\n",
      "Source IP\n",
      "Source Port\n",
      "Destination IP\n",
      "Destination Port\n",
      "Protocol\n",
      "Timestamp\n",
      "Flow Duration\n",
      "Total Fwd Packets\n",
      "Total Backward Packets\n",
      "Total Length of Fwd Packets\n",
      "Total Length of Bwd Packets\n",
      "Fwd Packet Length Max\n",
      "Fwd Packet Length Min\n",
      "Fwd Packet Length Mean\n",
      "Fwd Packet Length Std\n",
      "Bwd Packet Length Max\n",
      "Bwd Packet Length Min\n",
      "Bwd Packet Length Mean\n",
      "Bwd Packet Length Std\n",
      "Flow Bytes/s\n",
      "Flow Packets/s\n",
      "Flow IAT Mean\n",
      "Flow IAT Std\n",
      "Flow IAT Max\n",
      "Flow IAT Min\n",
      "Fwd IAT Total\n",
      "Fwd IAT Mean\n",
      "Fwd IAT Std\n",
      "Fwd IAT Max\n",
      "Fwd IAT Min\n",
      "Bwd IAT Total\n",
      "Bwd IAT Mean\n",
      "Bwd IAT Std\n",
      "Bwd IAT Max\n",
      "Bwd IAT Min\n",
      "Fwd PSH Flags\n",
      "Bwd PSH Flags\n",
      "Fwd URG Flags\n",
      "Bwd URG Flags\n",
      "Fwd Header Length\n",
      "Bwd Header Length\n",
      "Fwd Packets/s\n",
      "Bwd Packets/s\n",
      "Min Packet Length\n",
      "Max Packet Length\n",
      "Packet Length Mean\n",
      "Packet Length Std\n",
      "Packet Length Variance\n",
      "FIN Flag Count\n",
      "SYN Flag Count\n",
      "RST Flag Count\n",
      "PSH Flag Count\n",
      "ACK Flag Count\n",
      "URG Flag Count\n",
      "CWE Flag Count\n",
      "ECE Flag Count\n",
      "Down/Up Ratio\n",
      "Average Packet Size\n",
      "Avg Fwd Segment Size\n",
      "Avg Bwd Segment Size\n",
      "Fwd Header Length.1\n",
      "Fwd Avg Bytes/Bulk\n",
      "Fwd Avg Packets/Bulk\n",
      "Fwd Avg Bulk Rate\n",
      "Bwd Avg Bytes/Bulk\n",
      "Bwd Avg Packets/Bulk\n",
      "Bwd Avg Bulk Rate\n",
      "Subflow Fwd Packets\n",
      "Subflow Fwd Bytes\n",
      "Subflow Bwd Packets\n",
      "Subflow Bwd Bytes\n",
      "Init_Win_bytes_forward\n",
      "Init_Win_bytes_backward\n",
      "act_data_pkt_fwd\n",
      "min_seg_size_forward\n",
      "Active Mean\n",
      "Active Std\n",
      "Active Max\n",
      "Active Min\n",
      "Idle Mean\n",
      "Idle Std\n",
      "Idle Max\n",
      "Idle Min\n",
      "Label\n"
     ]
    }
   ],
   "source": [
    "print('Columns:')\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! Let's move on, then.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Categories\n",
    "This 'Label' column is where we are going to see the category each classification is in. As is, if we go through the dataset and output all of the values we see in this data set (next cell), we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADWARE_GOOLIGAN    93772\n",
       "ADWARE_FEIWO       56632\n",
       "ADWARE_EWIND       43374\n",
       "ADWARE_DOWGIN      39682\n",
       "ADWARE_SHUANET     39271\n",
       "ADWARE_KEMOGE      38771\n",
       "ADWARE_YOUMI       36035\n",
       "ADWARE_KOODOUS     32547\n",
       "ADWARE_MOBIDASH    31034\n",
       "ADWARE_SELFMITE    13029\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since our research problem at the moment is to just classify between 'Adware', 'Benign', etc, we don't need all of these types of 'Adware'. We can remedy this by using the next block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = 'ADWARE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I love you, `pandas`. Now let's look at the 'Label' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADWARE    424147\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to a File\n",
    "All we have to do now is output this data to a file (`full_features_full_data.csv`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'full_features_full_data.csv'\n",
    "df.to_csv(path + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating the Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to complete this process for every other category that we have. Let's look at the list real quick:\n",
    "- <strike>Adware</strike>\n",
    "- Benign\n",
    "- Ransomware\n",
    "- Scareware\n",
    "- SMSmalware\n",
    "\n",
    "That's an awful lot! Let's streamline this process a bit by using a loop. Now that we've walked through all of the steps for 'Adware', it's essentially the same thing for each category. The only things we have to change are the file/category names and the way we output to the `full_features_full_data.csv` file. \n",
    "\n",
    "Since the previous cell created/overwrites any file we have, if we run it for the next category, we will destroy all of our work so far. To prevent this, we can add the `mode='a'` argument to the `to_csv` method to only `append` the data. Also, since the headers are added by default, and they're already there because of the previous cell, we'll add `headers=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Benign\n",
      "\tReading in the data...done\n",
      "\tRenaming columns with spaces...done\n",
      "\tWriting to full_features_full_data.csv...done\n",
      "Benign completed\n",
      "Working on Ransomware\n",
      "\tReading in the data...done\n",
      "\tRenaming columns with spaces...done\n",
      "\tWriting to full_features_full_data.csv...done\n",
      "Ransomware completed\n",
      "Working on Scareware\n",
      "\tReading in the data...done\n",
      "\tRenaming columns with spaces...done\n",
      "\tWriting to full_features_full_data.csv...done\n",
      "Scareware completed\n",
      "Working on SMSmalware\n",
      "\tReading in the data...done\n",
      "\tRenaming columns with spaces...done\n",
      "\tWriting to full_features_full_data.csv...done\n",
      "SMSmalware completed\n",
      "All imports and writing complete!\n"
     ]
    }
   ],
   "source": [
    "categories = ['Benign', 'Ransomware', 'Scareware', 'SMSmalware']\n",
    "for cat in categories:\n",
    "    print('Working on {}'.format(cat))\n",
    "    print('\\tReading in the data...', end='')\n",
    "    templist = []\n",
    "    allFiles = glob.glob(path + '/{}/*/*.csv'.format(cat))\n",
    "    frame = pd.DataFrame()\n",
    "    \n",
    "    for fille in allFiles:\n",
    "        df = pd.read_csv(fille, index_col=None, header=0)\n",
    "        templist.append(df)\n",
    "    frame = pd.concat(templist)\n",
    "    print('done')\n",
    "\n",
    "    df = frame\n",
    "    \n",
    "    # Remove the spaces in front of some of the column names\n",
    "    #  Without this, it is really annoying to try to pull up a column with random spaces in the front\n",
    "    print('\\tRenaming columns with spaces...', end='')\n",
    "    cols = {}\n",
    "    for name in df.columns:\n",
    "        if name[0] is ' ':\n",
    "            cols[name] = name[1:]\n",
    "    df.rename(cols, axis=1, inplace=True, errors='raise')\n",
    "    print('done')\n",
    "    \n",
    "    df['Label'] = cat.upper()\n",
    "    \n",
    "    print('\\tWriting to {}...'.format(filename), end='')\n",
    "    df.to_csv(path + filename, mode='a', header=False)\n",
    "    print('done')\n",
    "    \n",
    "    print('{} completed'.format(cat))\n",
    "print('All imports and writing complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trust but Verify\n",
    "Let's import the datafile and make sure it has all of the categories that we want. Note that this cell will likely take a lot longer since it is much using a much larger file!  \n",
    "\n",
    "I cannot run this in my Jupyter Notebook without killing the kernel, due to this I've put the code and output in this cell instead of a cell that I cannot run.  \n",
    "\n",
    "```\n",
    "$ python -i\n",
    ">>> import pandas as pd\n",
    ">>> df = pd.read_csv(path + filename)\n",
    ">>> df['Label'].value_counts()\n",
    "BENIGN        1205515\n",
    "ADWARE         424147\n",
    "SCAREWARE      400841\n",
    "RANSOMWARE     348943\n",
    "SMSMALWARE     237133\n",
    "Name: Label, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's move on to some `feature selection`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
