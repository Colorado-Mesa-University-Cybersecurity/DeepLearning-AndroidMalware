{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check\n",
    "This notebook is meant to act as a sanity check to make sure that the techniques we are using for the CIC-AndMal2017 dataset are sound. The techniques will be used on well-known datasets, such as the `iris` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "This section will mainly focus on the loading up and splitting of the data into training and testing sets. This will allow us to fit the models we want to train and test their performance with the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Technique from https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "print(data.target[[10, 25, 50]])\n",
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the exact output we expect from this example. We will now move on to looking at the characteristics of the dataset and separating the data out into training and testing sets using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in the iris dataset:\n",
      "\t1. sepal length (cm)\n",
      "\t2. sepal width (cm)\n",
      "\t3. petal length (cm)\n",
      "\t4. petal width (cm)\n"
     ]
    }
   ],
   "source": [
    "print('Features in the iris dataset:')\n",
    "\n",
    "n=1\n",
    "for feature in data.feature_names:\n",
    "    print('\\t{}. {}'.format(n, feature))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 of the samples from the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.9\t\t\t3.0\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.7\t\t\t3.2\t\t\t1.3\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.6\t\t\t3.1\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.0\t\t\t3.6\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.4\t\t\t3.9\t\t\t1.7\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.6\t\t\t3.4\t\t\t1.4\t\t\t0.3\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.0\t\t\t3.4\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.4\t\t\t2.9\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# These are the color codes for the train and test outputs\n",
    "train_color = '\\x1b[34m'\n",
    "test_color = '\\x1b[31m'\n",
    "\n",
    "def sample_in_training(sample):\n",
    "    \"\"\"\n",
    "    Determines if a given array of data is in the X_train set\n",
    "    \"\"\"\n",
    "    # For every value in the sample\n",
    "    #print('Sample received: {}'.format(sample))\n",
    "    if list(sample) in X_train.tolist():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def sample_in_testing(sample):\n",
    "    \"\"\"\n",
    "    Determines if a given array of data is in the X_test set\n",
    "    \"\"\"\n",
    "    # For every value in the sample\n",
    "    #print('Sample received: {}'.format(sample))\n",
    "    if list(sample) in X_test.tolist():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def print_header(db, clss=False):\n",
    "    \"\"\"\n",
    "    Function to print the header of the data bunch provided\n",
    "    \"\"\"\n",
    "    for feature in db.feature_names:\n",
    "        print('\\t{}'.format(feature), end='')\n",
    "    if clss:\n",
    "        print('\\tclassification')\n",
    "    print('\\n', end='')\n",
    "    \n",
    "def print_databunch(db, count):\n",
    "    \"\"\"\n",
    "    Function to print the entire length of the data bunch provided\n",
    "    \n",
    "    Args:\n",
    "      db    => The narray, requires data and target elements\n",
    "      count => Number of instances wanting to print out or 'all'\n",
    "    \"\"\"\n",
    "    instances = db.data\n",
    "    print('Here are {} of the samples from the data:'.format(count))\n",
    "    print_header(db, clss=True)\n",
    "    for sample in range(count if count != 'all' else len(instances)):\n",
    "        # If the sample is in the training set, print it in blue\n",
    "        if 'X_train' in globals() and sample_in_training(db.data[sample]):\n",
    "            print(train_color, end='')\n",
    "        # If the sample is in the testing set, print it in green\n",
    "        elif 'X_test' in globals() and sample_in_testing(db.data[sample]):\n",
    "            print(test_color, end='')\n",
    "            \n",
    "        # The first value needs padding of one tab\n",
    "        print('\\t', end='')\n",
    "        \n",
    "        # For every value in the sample\n",
    "        for val in db.data[sample]:\n",
    "            print('{}'.format(val), end='\\t\\t\\t')\n",
    "        \n",
    "        # Print the classification at the end\n",
    "        print('{}'.format(db.target_names[db.target[sample]]))\n",
    "        \n",
    "        # End of the sample\n",
    "        print('\\n', end='')\n",
    "        \n",
    "        # Print in black now\n",
    "        print('\\x1b[0m', end='')\n",
    "        \n",
    "print_databunch(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've printed out quite a few of the instances (all of them, really). Take note of the first ten instances, we'll see them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "Now, using the `train_test_split` function, provided by the `sklearn` library, we will split up the dataset we've been provided and use both sections later. The dataset contains 150 instances, meaning if we split dataset to allocate 20% (30 samples) of the available data for testing the models, we will be left with 80% (120 samples) to train the models. An additional concern of ours stems from the fact that the dataset contains multiple classifications with specific ratios within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 150\n",
      "Number of classifications: 3 (['setosa' 'versicolor' 'virginica'])\n",
      "Proportions within the dataset:\n",
      "\n",
      "\tsetosa\tversicolor\tvirginica\t\n",
      "\t50\t50\t\t50\n"
     ]
    }
   ],
   "source": [
    "tgt = data.target\n",
    "print('Length of data: {}'.format(len(tgt)))\n",
    "print('Number of classifications: {} ({})'.format(len(data.target_names), data.target_names))\n",
    "tgt1 = []\n",
    "tgt2 = []\n",
    "tgt3 = []\n",
    "for val in tgt:\n",
    "    # Is the classification 'setosa'?\n",
    "    if val == 0:\n",
    "        tgt1.append(val)\n",
    "    # Is the classification 'versicolor'?\n",
    "    elif val == 1:\n",
    "        tgt2.append(val)\n",
    "    # Is the classification 'virginica'?\n",
    "    elif val == 2:\n",
    "        tgt3.append(val)\n",
    "        \n",
    "print('Proportions within the dataset:\\n')\n",
    "print('\\t', end='')\n",
    "for clss in data.target_names:\n",
    "    print(clss, end='\\t')\n",
    "print('\\n', end='')\n",
    "print('\\t{}\\t{}\\t\\t{}'.format(len(tgt1), len(tgt2), len(tgt3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, all of the classifications within the dataset are balanced (1:1). When we split this data up, we want to make sure this proportion stays the same for each split. If we don't do this, we could end up with models training or being tested on data that is unrepresentative of the entire dataset. In the worst-case scenario, this would be similar to teaching a kid *math* and then testing them in *Spanish*.  \n",
    "\n",
    "This 'stratification' problem can be easily resolved with the `stratify` argument in the `train_test_split` function. We will hand the argument the target classification and it will find the probabilities to maintain when splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before splitting:\n",
      "\tNumber of samples: 150\n",
      "After splitting:\n",
      "\tNumber of training samples: 120\n",
      "\tNumber of testing samples: 30\n"
     ]
    }
   ],
   "source": [
    "# Documentation for this function found here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the random state for reproducibility\n",
    "random_state = 1\n",
    "\n",
    "# Separate out the data in X (data) and y (target)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print('Before splitting:')\n",
    "print('\\tNumber of samples: {}'.format(len(X)))\n",
    "\n",
    "# Split up the data and target variables into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=random_state, stratify=y)\n",
    "\n",
    "print('After splitting:')\n",
    "print('\\tNumber of training samples: {}'.format(len(X_train)))\n",
    "print('\\tNumber of testing samples: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust but Verify\n",
    "Let's verify that the data *did* get split up. We'll print them out in a similar way to what we did last time, however now the data types have changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data before splitting: <class 'sklearn.utils.Bunch'>\n",
      "Type of data after splitting : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of data before splitting: {}'.format(type(data)))\n",
    "print('Type of data after splitting : {}'.format(type(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this change in data type, I need to recreate these functions that print out the data. We also now have the targets and the training data split up, which makes the printing of the data a little more annoying since we need to keep track of the targets and the data separately. However, we will cheat a little and use the same header function because I don't think we can get that information out of the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTraining data:\n",
      "There are 10 samples in the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t5.1\t\t\t3.7\t\t\t1.5\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\t4.6\t\t\t3.2\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t6.9\t\t\t3.1\t\t\t5.1\t\t\t2.3\t\t\tvirginica\n",
      "\n",
      "\t5.5\t\t\t2.6\t\t\t4.4\t\t\t1.2\t\t\tversicolor\n",
      "\n",
      "\t5.6\t\t\t2.9\t\t\t3.6\t\t\t1.3\t\t\tversicolor\n",
      "\n",
      "\t6.0\t\t\t3.4\t\t\t4.5\t\t\t1.6\t\t\tversicolor\n",
      "\n",
      "\t6.3\t\t\t2.3\t\t\t4.4\t\t\t1.3\t\t\tversicolor\n",
      "\n",
      "\t6.0\t\t\t2.2\t\t\t5.0\t\t\t1.5\t\t\tvirginica\n",
      "\n",
      "\t6.3\t\t\t3.4\t\t\t5.6\t\t\t2.4\t\t\tvirginica\n",
      "\n",
      "\t6.9\t\t\t3.1\t\t\t4.9\t\t\t1.5\t\t\tversicolor\n",
      "\n",
      "\u001b[0m\u001b[31mTesting data:\n",
      "There are 10 samples in the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t7.3\t\t\t2.9\t\t\t6.3\t\t\t1.8\t\t\tvirginica\n",
      "\n",
      "\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\t5.1\t\t\t2.5\t\t\t3.0\t\t\t1.1\t\t\tversicolor\n",
      "\n",
      "\t4.8\t\t\t3.4\t\t\t1.6\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t5.0\t\t\t3.5\t\t\t1.6\t\t\t0.6\t\t\tsetosa\n",
      "\n",
      "\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t6.2\t\t\t3.4\t\t\t5.4\t\t\t2.3\t\t\tvirginica\n",
      "\n",
      "\t6.4\t\t\t2.7\t\t\t5.3\t\t\t1.9\t\t\tvirginica\n",
      "\n",
      "\t5.6\t\t\t2.8\t\t\t4.9\t\t\t2.0\t\t\tvirginica\n",
      "\n",
      "\t6.8\t\t\t2.8\t\t\t4.8\t\t\t1.4\t\t\tversicolor\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "def print_arr(dat, cat):\n",
    "    \"\"\"\n",
    "    Function to print the entire length of the data arrays\n",
    "    \n",
    "    Args:\n",
    "      dat => The ndarray that holds the data (Ex. X_train or X_test)\n",
    "      cat => The ndarray that holds the targets/classes (Ex. y_train or y_test)\n",
    "    \"\"\"\n",
    "    instances = len(dat)\n",
    "    print('There are {} samples in the data:'.format(instances))\n",
    "    print_header(data, clss=True)\n",
    "    for sample in range(instances):\n",
    "        print('\\t', end='')\n",
    "        for val in dat[sample]:\n",
    "            print('{}'.format(val), end='\\t\\t\\t')\n",
    "        print('{}'.format(data.target_names[cat[sample]]))\n",
    "        print('\\n', end='')\n",
    "        \n",
    "# Print all of the training data in blue\n",
    "print(train_color, end='')\n",
    "print('Training data:')\n",
    "print_arr(X_train[:10], y_train[:10])\n",
    "print('\\x1b[0m', end='')\n",
    "\n",
    "# Print all of the testing data in green\n",
    "print(test_color, end='')\n",
    "print('Testing data:')\n",
    "print_arr(X_test[:10], y_test[:10])\n",
    "print('\\x1b[0m', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print the original data and to see where the first ten instances went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 of the samples from the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\u001b[31m\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.9\t\t\t3.0\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.7\t\t\t3.2\t\t\t1.3\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.6\t\t\t3.1\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t5.0\t\t\t3.6\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t5.4\t\t\t3.9\t\t\t1.7\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.6\t\t\t3.4\t\t\t1.4\t\t\t0.3\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t5.0\t\t\t3.4\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t4.4\t\t\t2.9\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_databunch(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can see the where the first ten samples from the dataset went. Out of the first ten samples we see above, seen in red are the four samples that have gone to the testing set (`X_test` and `y_test`) and six, in blue, that have gone to the training set (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "Since we have now demonstrated the splitting of the `iris` dataset into training and testing sets, we can start fitting models on the training data. Here, we will use the `RandomForestClassifier`, `DecisionTreeClassifier`, and `KNeighborsClassifier` in an attempt to learn the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must create the models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models created.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, random_state=random_state)\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "print('Models created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit all of these models with the training data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier fit\n",
      "DecisionTreeClassifier fit\n",
      "KNeighborsClassifier fit\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "print('RandomForestClassifier fit')\n",
    "dt.fit(X_train, y_train)\n",
    "print('DecisionTreeClassifier fit')\n",
    "knn.fit(X_train, y_train)\n",
    "print('KNeighborsClassifier fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we must evaluate the performance of the models on the testing data (`X_test`)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance:\n",
      "\n",
      "\tModel\tAccuracy\n",
      "\t----------------\n",
      "\tRF\t96.67%\n",
      "\tDT\t96.67%\n",
      "\tkNN\t96.67%\n"
     ]
    }
   ],
   "source": [
    "results_rf = rf.score(X_test, y_test)\n",
    "results_dt = dt.score(X_test, y_test)\n",
    "results_knn = knn.score(X_test, y_test)\n",
    "\n",
    "print('Model performance:\\n')\n",
    "print('\\tModel\\tAccuracy')\n",
    "print('\\t' + '-'*16)\n",
    "print('\\tRF\\t{:.2f}%'.format(100*results_rf))\n",
    "print('\\tDT\\t{:.2f}%'.format(100*results_dt))\n",
    "print('\\tkNN\\t{:.2f}%'.format(100*results_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see pretty high-performing models here! This accuracy of 96% is expected for this dataset and it has been thoroughly studied. All we've done so far is demonstrate our methods for loading the data, creating and training the models, and finally evaluating their performance on a testing dataset. We will move on to evaluate a deep learning model in an attempt to match this high performance above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Implementation\n",
    "We will be using the `keras` library to implement a deep neural network with the goal of learning this `iris` dataset. First, we will import the type of model, the layers required, and some metrics for our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.metrics import CategoricalAccuracy, Precision, Recall\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Unlike the `sklearn` models above, we need to change the way we represent the `y` data so we can interpret the model's predictions. Let's look at how the `y` values are represented right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train values:\n",
      "[0 0 2 1 1 1 1 2 2 1 2 0 1 1 2 0 2 1 1 0 0 2 2 1 2 2 0 0 2 0 0 0 0 2 0 1 2\n",
      " 1 2 2 1 1 2 2 1 1 2 1 1 0 2 0 2 0 0 1 0 1 2 0 2 0 0 2 2 0 1 0 0 1 2 1 1 0\n",
      " 0 1 2 1 1 2 1 2 0 1 2 1 1 0 0 2 1 2 1 0 1 2 2 0 0 2 2 0 2 1 1 1 2 0 2 1 2\n",
      " 0 2 0 1 0 1 0 0 0]\n",
      "y_test values:\n",
      "[2 0 1 0 0 0 2 2 2 1 0 1 2 1 2 0 2 1 1 2 1 1 0 0 2 2 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print('y_train values:')\n",
    "print(y_train)\n",
    "\n",
    "print('y_test values:')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way of turn this regression problem into a classification problem. We want the output layer of the neural network to have three nodes, one for each classification. To complete this, we can use the function `to_categorical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at how the `y` data is represented now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train values:\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "y_test values:\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('y_train values:')\n",
    "print(y_train)\n",
    "\n",
    "print('y_test values:')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the representation of the `y` is now a lot different, all the model has to do is activate a node predict a given class. Every sample now has three options, which is exactly what we want to see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the DNN Model\n",
    "Now with the preprocessing out of the way, we can move on to building and testing the model fairly quickly.   \n",
    "\n",
    "We need to know the size of the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = CategoricalAccuracy() \n",
    "prec = Precision()\n",
    "rec = Recall()\n",
    "metrics = [accuracy, prec, rec]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(4,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the DNN\n",
    "Below, similar to how we did for the `sklearn` models above, we will fit the `keras` DNN model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f667c1a50d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=20, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the DNN\n",
    "The code for evaluating the performance of the DNN is similar to the `sklearn` techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n",
      "Loss: 21.696974\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n"
     ]
    }
   ],
   "source": [
    "results_dnn = model.evaluate(X_test, y_test, verbose=0)\n",
    "acc, loss, prec, rec = results_dnn[1]*100, results_dnn[0]*100, results_dnn[2], results_dnn[3]\n",
    "print('Accuracy: {:.2f}%'.format(acc))\n",
    "print('Loss: {:2f}'.format(loss))\n",
    "print('Precision: {:.2f}'.format(prec))\n",
    "print('Recall: {:.2f}'.format(rec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the DNN's performance metrics above, we've matched the performance of all three of the `sklearn` models above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
