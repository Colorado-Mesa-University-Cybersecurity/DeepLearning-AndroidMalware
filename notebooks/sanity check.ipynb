{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check\n",
    "This notebook is meant to act as a sanity check to make sure that the techniques we are using for the CIC-AndMal2017 dataset are sound. The techniques will be used on well-known datasets, such as the `iris` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Splitting the Data\n",
    "This section will mainly focus on the loading up and splitting of the data into training and testing sets. This will allow us to fit the models we want to train and test their performance with the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Technique from https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "print(data.target[[10, 25, 50]])\n",
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the exact output we expect from this example. We will now move on to looking at the characteristics of the dataset and separating the data out into training and testing sets using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in the iris dataset:\n",
      "\t1. sepal length (cm)\n",
      "\t2. sepal width (cm)\n",
      "\t3. petal length (cm)\n",
      "\t4. petal width (cm)\n"
     ]
    }
   ],
   "source": [
    "print('Features in the iris dataset:')\n",
    "\n",
    "n=1\n",
    "for feature in data.feature_names:\n",
    "    print('\\t{}. {}'.format(n, feature))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 of the samples from the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.9\t\t\t3.0\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.7\t\t\t3.2\t\t\t1.3\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.6\t\t\t3.1\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.0\t\t\t3.6\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.4\t\t\t3.9\t\t\t1.7\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.6\t\t\t3.4\t\t\t1.4\t\t\t0.3\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t5.0\t\t\t3.4\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.4\t\t\t2.9\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# These are the color codes for the train and test outputs\n",
    "train_color = '\\x1b[34m'\n",
    "test_color = '\\x1b[31m'\n",
    "\n",
    "def sample_in_training(sample):\n",
    "    \"\"\"\n",
    "    Determines if a given array of data is in the X_train set\n",
    "    \"\"\"\n",
    "    # For every value in the sample\n",
    "    #print('Sample received: {}'.format(sample))\n",
    "    if list(sample) in X_train.tolist():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def sample_in_testing(sample):\n",
    "    \"\"\"\n",
    "    Determines if a given array of data is in the X_test set\n",
    "    \"\"\"\n",
    "    # For every value in the sample\n",
    "    #print('Sample received: {}'.format(sample))\n",
    "    if list(sample) in X_test.tolist():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def print_header(db, clss=False):\n",
    "    \"\"\"\n",
    "    Function to print the header of the data bunch provided\n",
    "    \"\"\"\n",
    "    for feature in db.feature_names:\n",
    "        print('\\t{}'.format(feature), end='')\n",
    "    if clss:\n",
    "        print('\\tclassification')\n",
    "    print('\\n', end='')\n",
    "    \n",
    "def print_databunch(db, count):\n",
    "    \"\"\"\n",
    "    Function to print the entire length of the data bunch provided\n",
    "    \n",
    "    Args:\n",
    "      db    => The narray, requires data and target elements\n",
    "      count => Number of instances wanting to print out or 'all'\n",
    "    \"\"\"\n",
    "    instances = db.data\n",
    "    print('Here are {} of the samples from the data:'.format(count))\n",
    "    print_header(db, clss=True)\n",
    "    for sample in range(count if count != 'all' else len(instances)):\n",
    "        # If the sample is in the training set, print it in blue\n",
    "        if 'X_train' in globals() and sample_in_training(db.data[sample]):\n",
    "            print(train_color, end='')\n",
    "        # If the sample is in the testing set, print it in green\n",
    "        elif 'X_test' in globals() and sample_in_testing(db.data[sample]):\n",
    "            print(test_color, end='')\n",
    "            \n",
    "        # The first value needs padding of one tab\n",
    "        print('\\t', end='')\n",
    "        \n",
    "        # For every value in the sample\n",
    "        for val in db.data[sample]:\n",
    "            print('{}'.format(val), end='\\t\\t\\t')\n",
    "        \n",
    "        # Print the classification at the end\n",
    "        print('{}'.format(db.target_names[db.target[sample]]))\n",
    "        \n",
    "        # End of the sample\n",
    "        print('\\n', end='')\n",
    "        \n",
    "        # Print in black now\n",
    "        print('\\x1b[0m', end='')\n",
    "        \n",
    "print_databunch(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've printed out quite a few of the instances (all of them, really). Take note of the first ten instances, we'll see them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:\n",
      "150\n",
      "y shape:\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# Documentation for this function found here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the random state for reproducibility\n",
    "random_state = 1\n",
    "\n",
    "# Separate out the data in X (data) and y (target)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print('X shape:')\n",
    "print(X.shape[0])\n",
    "\n",
    "print('y shape:')\n",
    "print(y.shape[0])\n",
    "\n",
    "# Split up the data and target variables into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the sizes and compositions of each set of data. We'll print them out in a similar way to what we did last time, however now the data types have changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data before splitting: <class 'sklearn.utils.Bunch'>\n",
      "Type of data after splitting : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of data before splitting: {}'.format(type(data)))\n",
    "print('Type of data after splitting : {}'.format(type(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this change in data type, I need to recreate these functions that print out the data. We also now have the targets and the training data split up, which makes the printing of the data a little more annoying since we need to keep track of the targets and the data separately. However, we will cheat a little and use the same header function because I don't think we can get that information out of the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTraining data:\n",
      "There are 10 samples in the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t5.1\t\t\t3.7\t\t\t1.5\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\t4.6\t\t\t3.2\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t6.9\t\t\t3.1\t\t\t5.1\t\t\t2.3\t\t\tvirginica\n",
      "\n",
      "\t5.5\t\t\t2.6\t\t\t4.4\t\t\t1.2\t\t\tversicolor\n",
      "\n",
      "\t5.6\t\t\t2.9\t\t\t3.6\t\t\t1.3\t\t\tversicolor\n",
      "\n",
      "\t6.0\t\t\t3.4\t\t\t4.5\t\t\t1.6\t\t\tversicolor\n",
      "\n",
      "\t6.3\t\t\t2.3\t\t\t4.4\t\t\t1.3\t\t\tversicolor\n",
      "\n",
      "\t6.0\t\t\t2.2\t\t\t5.0\t\t\t1.5\t\t\tvirginica\n",
      "\n",
      "\t6.3\t\t\t3.4\t\t\t5.6\t\t\t2.4\t\t\tvirginica\n",
      "\n",
      "\t6.9\t\t\t3.1\t\t\t4.9\t\t\t1.5\t\t\tversicolor\n",
      "\n",
      "\u001b[0m\u001b[31mTesting data:\n",
      "There are 10 samples in the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\t7.3\t\t\t2.9\t\t\t6.3\t\t\t1.8\t\t\tvirginica\n",
      "\n",
      "\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\t5.1\t\t\t2.5\t\t\t3.0\t\t\t1.1\t\t\tversicolor\n",
      "\n",
      "\t4.8\t\t\t3.4\t\t\t1.6\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t5.0\t\t\t3.5\t\t\t1.6\t\t\t0.6\t\t\tsetosa\n",
      "\n",
      "\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\t6.2\t\t\t3.4\t\t\t5.4\t\t\t2.3\t\t\tvirginica\n",
      "\n",
      "\t6.4\t\t\t2.7\t\t\t5.3\t\t\t1.9\t\t\tvirginica\n",
      "\n",
      "\t5.6\t\t\t2.8\t\t\t4.9\t\t\t2.0\t\t\tvirginica\n",
      "\n",
      "\t6.8\t\t\t2.8\t\t\t4.8\t\t\t1.4\t\t\tversicolor\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "def print_arr(dat, cat):\n",
    "    \"\"\"\n",
    "    Function to print the entire length of the data arrays\n",
    "    \n",
    "    Args:\n",
    "      dat => The ndarray that holds the data (Ex. X_train or X_test)\n",
    "      cat => The ndarray that holds the targets/classes (Ex. y_train or y_test)\n",
    "    \"\"\"\n",
    "    instances = len(dat)\n",
    "    print('There are {} samples in the data:'.format(instances))\n",
    "    print_header(data, clss=True)\n",
    "    for sample in range(instances):\n",
    "        print('\\t', end='')\n",
    "        for val in dat[sample]:\n",
    "            print('{}'.format(val), end='\\t\\t\\t')\n",
    "        print('{}'.format(data.target_names[cat[sample]]))\n",
    "        print('\\n', end='')\n",
    "        \n",
    "# Print all of the training data in blue\n",
    "print(train_color, end='')\n",
    "print('Training data:')\n",
    "print_arr(X_train[:10], y_train[:10])\n",
    "print('\\x1b[0m', end='')\n",
    "\n",
    "# Print all of the testing data in green\n",
    "print(test_color, end='')\n",
    "print('Testing data:')\n",
    "print_arr(X_test[:10], y_test[:10])\n",
    "print('\\x1b[0m', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print the original data and to see where the first ten instances went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 of the samples from the data:\n",
      "\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\tclassification\n",
      "\n",
      "\u001b[31m\t5.1\t\t\t3.5\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.9\t\t\t3.0\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.7\t\t\t3.2\t\t\t1.3\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.6\t\t\t3.1\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t5.0\t\t\t3.6\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t5.4\t\t\t3.9\t\t\t1.7\t\t\t0.4\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t4.6\t\t\t3.4\t\t\t1.4\t\t\t0.3\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[34m\t5.0\t\t\t3.4\t\t\t1.5\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t4.4\t\t\t2.9\t\t\t1.4\t\t\t0.2\t\t\tsetosa\n",
      "\n",
      "\u001b[0m\u001b[31m\t4.9\t\t\t3.1\t\t\t1.5\t\t\t0.1\t\t\tsetosa\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "print_databunch(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can see the data that we saw before from the data bunch with color coding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
