{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.metrics import CategoricalAccuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical, normalize\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('Imports complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulls in the dataset from a previously-saved csv\n",
    "df = pd.read_csv('../../malware_dataset/complete_categorized_dataset_cleaned.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label_categorized_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'Label_categorized_1'\n",
    "model_name = 'init'\n",
    "cont_names = list( set(df.columns) - set([dep_var]) )\n",
    "#print(cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[dep_var])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set df_y (datafold-y values) to the target classification 'dep_var' and remove this column from df\n",
    "#   x_data ~= df\n",
    "#   y_data ~= df_y\n",
    "df_y = df[dep_var]\n",
    "del df[dep_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Encodes target classifications from 0 to n-1 integers (only use for target classifications)\n",
    "#encoder = LabelEncoder()\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_y)\n",
    "\n",
    "# Transforms the y data to be encoded\n",
    "data_y = encoder.transform(df_y)\n",
    "data_y = to_categorical(data_y)\"\"\"\n",
    "\n",
    "\"\"\"# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "data_y = encoder.fit_transform(df_y)\n",
    "encoded_Y = encoder.transform(df_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "data_y = to_categorical(encoded_Y)\"\"\"\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data_y = label_encoder.fit_transform(df_y)\n",
    "\n",
    "# Normalize the x data\n",
    "data_x = (df - df.mean()) / (df.max() - df.min())\n",
    "data_x = data_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 1\n",
    "total_folds = 10\n",
    "\n",
    "# Stratified K-fold here because 10-fold cv is generally recommended and Stratified will maintain the \n",
    "#  target classification categorical balances for each fold\n",
    "for train_idx, test_idx in StratifiedKFold(n_splits=total_folds, shuffle=True, random_state=1).split(data_x, data_y):\n",
    "    print('Fold {}/{}'.format(fold_num, total_folds))\n",
    "    fold_num += 1\n",
    "    \n",
    "    data_y = to_categorical(data_y)\n",
    "\n",
    "    # Set up the training and testing sets\n",
    "    X_train, X_test = data_x[train_idx], data_x[test_idx]\n",
    "    y_train, y_test = data_y[train_idx], data_y[test_idx]\n",
    "\n",
    "    # Set up the metrics we want to collect\n",
    "    accuracy = CategoricalAccuracy() \t# Will change this to Categorical if the target classification is categorical\n",
    "    tp = TruePositives()\t\t# These could be collected with a confusion matrix, however translating back\n",
    "    tn = TrueNegatives()\t\t#  and forth from an image may be frustrating (it was last time I did it)\n",
    "    fp = FalsePositives()\n",
    "    fn = FalseNegatives()\n",
    "    metrics = [accuracy, tp, tn, fp, fn]\n",
    "\n",
    "    # The model must be reinitialized otherwise the model will have trained on all of the data (that wouldn't be true 10-fold cv)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(9,))) \t# Input layer, needs same shape as input data (9 values 1D)\n",
    "    model.add(Dense(64, activation='relu'))\t\t\t# Hidden layer of nodes\n",
    "    model.add(Dense(32, activation='relu'))\t\t\t# Hidden layer of nodes\n",
    "    model.add(Dense(5, activation='softmax'))\t\t\t# Output layer of only one node (on/off)\n",
    "\n",
    "    # \"Configures the model for training\"\n",
    "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    # Stochastic gradient descent and momentum optimizer.\n",
    "    sgd = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # mean squared error computes the mean of absolute difference between labels and predictions\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "    # Fit and test the model \n",
    "    model.fit(x=X_train, y=y_train, epochs=1, batch_size=512, verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Evaluate the performance of the model on the test set\n",
    "    scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "    #print(model.metrics_names)\n",
    "    #print('Scores values: {}'.format(scores))\n",
    "    acc, loss, tpn, tnn, fpn, fnn = scores[1]*100, scores[0]*100, scores[2], scores[3], scores[4], scores[5]\n",
    "    acc, loss = scores[1]*100, scores[0]*100\n",
    "    totaln = tpn + tnn + fpn + fnn\n",
    "    print('Baseline: accuracy: {:.2f}%: loss: {:2f}'.format(acc, loss))\n",
    "    print('\\tTrue Positive Rate: {} ({})'.format(tpn/totaln, tpn))\n",
    "    print('\\tTrue Negative Rate: {} ({})'.format(tnn/totaln, tnn))\n",
    "    print('\\tFalse Positive Rate: {} ({})'.format(fpn/totaln, fpn))\n",
    "    print('\\tFalse Negative Rate: {} ({})'.format(fnn/totaln, fnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
