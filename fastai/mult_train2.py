#!/bin/python3

from fastai.tabular import *
from fastai.metrics import Recall, Precision
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import shuffle
print('Imports complete')

# These are the malware types that we are concerned about
types = ['Adware', 'Ransomware', 'Scareware', 'SMSmalware']

# We want to train on each type of malware separately, trying to categorize between the species within each 
#  malware type. Ex. categorize between Shuanet or Gooligan species of Adware, but not Shuanet-Adware and 
#  Jisut-Ransomware.
for typ in types:
    print('Training for {}'.format(typ))

    # Import the data from the given csv
    path='../../malware_dataset/{}_species.csv'.format(typ)
    df = pd.read_csv(path, index_col=0)
    
    # Outputs the top 5 samples from the datafold
    df.head()
    
    # Processes for fastai to do in the background
    procs = [FillMissing, Categorify, Normalize]
    
    # Set up some variables for easy use later
    dep_var = 'Label_categorized_2'			# This is the dependent variable, the target classification variable
    cont_names = list(set(df.columns) - set([dep_var]))	# List of all the column names (not the target class)

    
    # Copy the dataframe for a hacky solution to provide the TabularList.from_df() method with a full dataset
    data = df.copy()
    
    # Rip out the target classification column and save it
    df_y = df[dep_var]
    del df[dep_var]
    
    # Encode and transform the data 
    # Since the target classification is categorical, we need to have a way to interpret the neural network's output.
    #  In this case, we are assigning each possible output with an integer 0..n-1, another option would be to use one-hot
    #  encoding here. This may be explored further.
    encoder = LabelEncoder()
    encoder.fit(df_y)
    data_y = encoder.transform(df_y)
    
    # Normalize the x data and rename for consistency
    data_x = (df - df.mean()) / (df.max() - df.min())
    data_x = data_x.values
    
    # Set up the metrics we want to collect. I wanted TP,TN,FP,FN but that wasn't available. Recall and precision are still
    #  extremely helpful for evaluating the model
    metrics = [accuracy, Recall(), Precision()]
    
    # Keep track of the folds
    fold_num = 1
    total_folds = 10
    
    # Get the indices for the fold and train on that fold
    #  Our goal here is to implement statified 10-fold cross validation
    for train_idx, test_idx in StratifiedKFold(n_splits=total_folds, shuffle=True, random_state=1).split(data_x, data_y):
        # This will create the datafold the way we need to hand it to the tabular learner class
        data_fold = (TabularList.from_df(data, path=path, cont_names=cont_names, procs=procs)
                    .split_by_idxs(train_idx, test_idx)
                    .label_from_df(cols=dep_var)
                    .databunch())
    
        print('Fold {}/{}'.format(fold_num, total_folds))
        fold_num+=1
    
        # Create the learner
        model = tabular_learner(data_fold, layers=[128, 64, 32], metrics=metrics, callback_fns=ShowGraph, ps=0.5)

        # Increase the number of instances we are working with on a batch
        model.data.batch_size = 512
        
        # Fit the model for one cycle, this will output the statistics/metrics we wanted before for the provided out of sample data.
        #  I'm kind of hoping that's true, anyways. fastai doesn't appear to evaluate the metrics (besides loss) before completing 
        #  the epoch. 
        model.fit_one_cycle(cyc_len=1)
